version: '3.8'

# Qdrant and S3 are now using remote services (Qdrant Cloud + Cloudflare R2/AWS S3)
# Configure via environment variables in .env file

services:
  # API 服务
  api:
    build:
      context: ..
      dockerfile: Dockerfile
    container_name: emomo-api
    ports:
      - "${API_PORT:-8080}:8080"
    volumes:
      # Mount data directory (must contain ChineseBQB subdirectory)
      # On host: <project-root>/data/ChineseBQB should exist with image files
      # In container: /root/data/ChineseBQB will be accessible
      - ../data:/root/data
      - ../configs:/root/configs
    environment:
      # API Keys
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - JINA_API_KEY=${JINA_API_KEY}

      # Qdrant Cloud 配置
      - QDRANT_HOST=${QDRANT_HOST}
      - QDRANT_PORT=${QDRANT_PORT:-6334}
      - QDRANT_COLLECTION=${QDRANT_COLLECTION:-emomo}
      - QDRANT_API_KEY=${QDRANT_API_KEY}
      - QDRANT_USE_TLS=${QDRANT_USE_TLS:-true}

      # S3/R2 存储配置
      - STORAGE_TYPE=${STORAGE_TYPE:-s3compatible}
      - STORAGE_ENDPOINT=${STORAGE_ENDPOINT}
      - STORAGE_ACCESS_KEY=${STORAGE_ACCESS_KEY}
      - STORAGE_SECRET_KEY=${STORAGE_SECRET_KEY}
      - STORAGE_USE_SSL=${STORAGE_USE_SSL:-true}
      - STORAGE_BUCKET=${STORAGE_BUCKET:-memes}
      - STORAGE_REGION=${STORAGE_REGION:-}  # R2 使用 "auto"，AWS S3 使用具体 region
      - STORAGE_PUBLIC_URL=${STORAGE_PUBLIC_URL:-}  # 公开访问 URL

      # VLM 配置
      # VLM Configuration (supports any OpenAI-compatible API)
      - VLM_MODEL=${VLM_MODEL:-gpt-4o-mini}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - QUERY_EXPANSION_MODEL=${QUERY_EXPANSION_MODEL:-gpt-4o-mini}
      - SEARCH_SCORE_THRESHOLD=${SEARCH_SCORE_THRESHOLD:-0.0}

      # 数据库配置
      - DATABASE_DRIVER=${DATABASE_DRIVER:-sqlite}
      - DATABASE_PATH=${DATABASE_PATH:-/root/data/memes.db}

      # 可选配置
      - DATA_DIR=${DATA_DIR:-/root/data}
      - CONFIG_PATH=${CONFIG_PATH:-/root/configs/config.prod.yaml}
    restart: unless-stopped
    networks:
      - emomo-network
    labels:
      - "environment=${ENVIRONMENT:-production}"
      - "project=emomo"
      - "service=emomo-api"

  # Grafana Alloy for log collection
  alloy:
    image: grafana/alloy:latest
    container_name: emomo-alloy
    volumes:
      - ./alloy/config.alloy:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - alloy_data:/var/lib/alloy/data
    environment:
      - LOKI_URL=${LOKI_URL}
      - LOKI_USERNAME=${LOKI_USERNAME}
      - LOKI_PASSWORD=${LOKI_PASSWORD}
      - CLUSTER_NAME=${CLUSTER_NAME:-production}
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - HOSTNAME=${HOSTNAME:-emomo-prod}
    command:
      - run
      - --server.http.listen-addr=0.0.0.0:12345
      - --storage.path=/var/lib/alloy/data
      - /etc/alloy/config.alloy
    ports:
      - "12345:12345"  # Alloy UI
    restart: unless-stopped
    networks:
      - emomo-network
    labels:
      - "environment=${ENVIRONMENT:-production}"
      - "project=emomo"
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 64M
          cpus: '0.1'

volumes:
  alloy_data:

networks:
  emomo-network:
    driver: bridge
